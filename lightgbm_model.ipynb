{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Paths\n",
    "squares_dir = \"chess_images/squares/\"\n",
    "labels_dir = \"chess_images/labels/\"\n",
    "features_file = \"chess_images/prepared_data/lightgbm/features.npy\"\n",
    "labels_file = \"chess_images/prepared_data/lightgbm/labels.npy\"\n",
    "\n",
    "def extract_hog_features(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (60, 60))\n",
    "\n",
    "    fd, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "                cells_per_block=(2, 2), visualize=True)\n",
    "    return fd\n",
    "\n",
    "def load_label(labels_dir, subfolder, row, col):\n",
    "    label_path = os.path.join(labels_dir, subfolder, \"bw_board\", f\"r{row}_c{col}.csv\")\n",
    "    try:\n",
    "        with open(label_path, \"r\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Skip header\n",
    "            return next(reader)[0]  # \"white\", \"black\", or \"none\"\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Label not found: {label_path}\")\n",
    "        return \"none\"\n",
    "\n",
    "def parse_row_col(filename):\n",
    "    match = re.match(r\"r(\\d+)_c(\\d+)\", filename)\n",
    "    if match:\n",
    "        return int(match.group(1)), int(match.group(2))\n",
    "    else:\n",
    "        raise ValueError(f\"Filename format error: {filename}\")\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for subfolder in os.listdir(squares_dir):\n",
    "    subfolder_path = os.path.join(squares_dir, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for board_folder in os.listdir(subfolder_path):\n",
    "            board_path = os.path.join(subfolder_path, board_folder)\n",
    "            if os.path.isdir(board_path):\n",
    "                for square_image in os.listdir(board_path):\n",
    "                    if square_image.endswith(\".jpg\"):\n",
    "                        image_path = os.path.join(board_path, square_image)\n",
    "                        try:\n",
    "                            row, col = parse_row_col(square_image)\n",
    "                        except ValueError as e:\n",
    "                            print(e)\n",
    "                            continue\n",
    "\n",
    "                        features.append(extract_hog_features(image_path))\n",
    "                        labels.append(load_label(labels_dir, subfolder, row, col))\n",
    "\n",
    "# Save features and labels\n",
    "np.save(features_file, np.array(features))\n",
    "\n",
    "# Directly save labels as text to avoid numeric confusion (we'll encode later)\n",
    "np.save(labels_file, np.array(labels))\n",
    "\n",
    "print(f\"Saved features to {features_file}\")\n",
    "print(f\"Saved labels to {labels_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model and encoder saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "X = np.load(\"chess_images/prepared_data/lightgbm/features.npy\")\n",
    "y = np.load(\"chess_images/prepared_data/lightgbm/labels.npy\")\n",
    "\n",
    "# Encode labels (\"white\", \"black\", \"none\" → 0, 1, 2)\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split into train and validation sets (optional but recommended)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare datasets for LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "# Train LightGBM\n",
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 3,\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    # \"learning_rate\": 0.001,\n",
    "    # \"num_boost_round\": 500,\n",
    "    # \"num_leaves\": 50,\n",
    "    # \"max_depth\": 7,\n",
    "    # \"lambda_l1\": 0.1,\n",
    "    # \"lambda_l2\": 0.1,\n",
    "    # \"early_stopping_rounds\": 10\n",
    "}\n",
    "\n",
    "model = lgb.train(params, train_data, valid_sets=[train_data, val_data], num_boost_round=100)\n",
    "\n",
    "# Save model and label encoder\n",
    "model.save_model(\"chess_images/prepared_data/lightgbm_chess_model.txt\")\n",
    "\n",
    "import joblib\n",
    "joblib.dump(encoder, \"chess_images/prepared_data/label_encoder.pkl\")\n",
    "\n",
    "print(\"Training complete. Model and encoder saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1...\n",
      "Fold 1 multi_logloss: 0.0619\n",
      "Training on fold 2...\n",
      "Fold 2 multi_logloss: 0.0632\n",
      "Training on fold 3...\n",
      "Fold 3 multi_logloss: 0.0622\n",
      "Training on fold 4...\n",
      "Fold 4 multi_logloss: 0.0642\n",
      "Training on fold 5...\n",
      "Fold 5 multi_logloss: 0.0634\n",
      "Best model was from fold 1 with multi_logloss = 0.0619\n",
      "Best model saved as 'lightgbm_chess_model.txt'\n",
      "Cross-validation complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "X = np.load(\"chess_images/prepared_data/lightgbm/features.npy\")\n",
    "y = np.load(\"chess_images/prepared_data/lightgbm/labels.npy\")\n",
    "\n",
    "# Encode labels (\"white\", \"black\", \"none\" → 0, 1, 2)\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Save label encoder (you only need one, it’s the same for all folds)\n",
    "joblib.dump(encoder, \"chess_images/prepared_data/label_encoder.pkl\")\n",
    "\n",
    "# LightGBM parameters\n",
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 3,\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    # Add or adjust parameters if needed\n",
    "}\n",
    "\n",
    "# Set up 5-fold stratified cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_model = None\n",
    "best_loss = float(\"inf\")\n",
    "best_fold = None\n",
    "\n",
    "# Training and tracking across folds\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y), 1):\n",
    "    print(f\"Training on fold {fold}...\")\n",
    "\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    model = lgb.train(params, train_data, valid_sets=[train_data, val_data], num_boost_round=100)\n",
    "\n",
    "    # Get validation loss\n",
    "    loss = model.best_score[\"valid_1\"][\"multi_logloss\"]\n",
    "    print(f\"Fold {fold} multi_logloss: {loss:.4f}\")\n",
    "\n",
    "    # Check if this is the best fold so far\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_model = model\n",
    "        best_fold = fold\n",
    "\n",
    "# Save only the best fold's model\n",
    "if best_model is not None:\n",
    "    best_model.save_model(\"chess_images/prepared_data/lightgbm_chess_model.txt\")\n",
    "    print(f\"Best model was from fold {best_fold} with multi_logloss = {best_loss:.4f}\")\n",
    "    print(\"Best model saved as 'lightgbm_chess_model.txt'\")\n",
    "\n",
    "print(\"Cross-validation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated FEN: 2wwbwwb/wwb1bbw1/bwwbww1b/2w5/1b1b1b2/b2ww3/wb1bwb2/6b1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "\n",
    "# Load the trained LightGBM model and label encoder\n",
    "model = lgb.Booster(model_file='chess_images/prepared_data/lightgbm_chess_model.txt')\n",
    "encoder = joblib.load('chess_images/prepared_data/label_encoder.pkl')  # Load the label encoder used in training\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    image = cv2.resize(image, (60, 60))\n",
    "    fd, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "                cells_per_block=(2, 2), visualize=True)\n",
    "    feature_names = [f'feature_{i}' for i in range(len(fd))]\n",
    "    return pd.DataFrame([fd], columns=feature_names)\n",
    "\n",
    "def split_and_predict_fen_with_overlay(image_path, output_path='chess_images/overlay_result.jpg'):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    color_image = cv2.imread(image_path)  # For overlay\n",
    "    image = cv2.resize(image, (480, 480))\n",
    "    color_image = cv2.resize(color_image, (480, 480))\n",
    "\n",
    "    step = 60\n",
    "\n",
    "    # This mapping depends on how the labels were encoded (check your training script)\n",
    "    label_mapping_inverse = {\n",
    "        0: \"b\",   # none = empty square\n",
    "        1: \"1\",   # empty piece\n",
    "        2: \"w\"    # black piece\n",
    "    }\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for row in range(8):\n",
    "        row_data = []\n",
    "        for col in range(8):\n",
    "            square = image[row * step:(row + 1) * step, col * step:(col + 1) * step]\n",
    "            features_df = extract_hog_features(square)\n",
    "\n",
    "            # Predict class index (0, 1, 2) using LightGBM\n",
    "            predicted_class_idx = np.argmax(model.predict(features_df), axis=1)[0]\n",
    "\n",
    "            # Convert class index back to label using the encoder\n",
    "            label = label_mapping_inverse[predicted_class_idx]\n",
    "\n",
    "            row_data.append(label)\n",
    "\n",
    "            # Add overlay text\n",
    "            if label in ['w', 'b']:\n",
    "                text_color = (255, 255, 255) if label == 'w' else (0, 0, 0)\n",
    "                cv2.putText(color_image, label, (col * step + 20, row * step + 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2, cv2.LINE_AA)\n",
    "\n",
    "        # Convert row to compact FEN format (combine consecutive empty squares)\n",
    "        fen_row = ''.join(row_data)\n",
    "        compact_fen_row = ''\n",
    "        count = 0\n",
    "        for char in fen_row:\n",
    "            if char == '1':\n",
    "                count += 1\n",
    "            else:\n",
    "                if count > 0:\n",
    "                    compact_fen_row += str(count)\n",
    "                    count = 0\n",
    "                compact_fen_row += char\n",
    "        if count > 0:\n",
    "            compact_fen_row += str(count)\n",
    "\n",
    "        predictions.append(compact_fen_row)\n",
    "\n",
    "    # Join all rows into final FEN string\n",
    "    fen_result = '/'.join(predictions)\n",
    "    print(\"Generated FEN:\", fen_result)\n",
    "\n",
    "    # Save FEN to file\n",
    "    with open(\"generated_bw_fen.fen\", \"w\") as file:\n",
    "        file.write(fen_result)\n",
    "\n",
    "    # Save overlay image\n",
    "    cv2.imwrite(output_path, color_image)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'chess_images/test2.jpg'\n",
    "split_and_predict_fen_with_overlay(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raspberryturk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
