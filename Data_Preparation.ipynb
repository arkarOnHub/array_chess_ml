{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d59876b-54fc-4ec7-8926-90377e61e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc14c69-7519-4d86-b2a1-991df31f31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 64 60*60 squares from a 480*480 image chess board\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Base directory paths\n",
    "base_dir = \"chess_images/board_and_fen/\"\n",
    "output_dir = \"chess_images/squares/\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to resize the image to 480x480 if needed\n",
    "def resize_image_if_needed(image):\n",
    "    # Check if the image is not 480x480\n",
    "    if image.shape[0] != 480 or image.shape[1] != 480:\n",
    "        # print(f\"Resizing image to 480x480...\")\n",
    "        image = cv2.resize(image, (480, 480))\n",
    "    return image\n",
    "\n",
    "# Function to divide the board into 8x8 squares\n",
    "def split_chessboard(image_path, output_subfolder, board_name):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = resize_image_if_needed(image)  # Ensure the image is 480x480\n",
    "    step = 60  # Each square is 60x60\n",
    "    # Create a specific folder for each board inside the respective subfolder\n",
    "    board_output_dir = os.path.join(output_subfolder, board_name)\n",
    "    os.makedirs(board_output_dir, exist_ok=True)\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            square = image[i * step:(i + 1) * step, j * step:(j + 1) * step]\n",
    "            square_name = f\"r{i}_c{j}.jpg\"\n",
    "            cv2.imwrite(os.path.join(board_output_dir, square_name), square)\n",
    "\n",
    "# Process all images in all subfolders\n",
    "for subfolder in os.listdir(base_dir):\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "    if os.path.isdir(subfolder_path):  # Ensure it's a directory\n",
    "        # Create corresponding output subfolder\n",
    "        output_subfolder = os.path.join(output_dir, subfolder)\n",
    "        os.makedirs(output_subfolder, exist_ok=True)\n",
    "        for image_file in os.listdir(subfolder_path):\n",
    "            if image_file.endswith('.jpg') or image_file.endswith('.png'):\n",
    "                board_name = os.path.splitext(image_file)[0]\n",
    "                split_chessboard(os.path.join(subfolder_path, image_file), output_subfolder, board_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb85fc-6b5e-4fe7-870f-62f0c97523d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write a bw_fen by reading fen for each image\n",
    "\n",
    "import os\n",
    "\n",
    "def fen_to_bw(fen):\n",
    "    # Mapping of pieces to \"b\" (black) and \"w\" (white)\n",
    "    piece_map = {\n",
    "        'p': 'b', 'r': 'b', 'n': 'b', 'b': 'b', 'q': 'b', 'k': 'b',\n",
    "        'P': 'w', 'R': 'w', 'N': 'w', 'B': 'w', 'Q': 'w', 'K': 'w',\n",
    "    }\n",
    "\n",
    "    # Split the FEN string to focus only on the board layout (first part)\n",
    "    board, *_ = fen.split(' ')\n",
    "\n",
    "    # Replace pieces in the board layout with 'b', 'w', or retain numbers\n",
    "    bw_board = []\n",
    "    for char in board:\n",
    "        if char in piece_map:\n",
    "            bw_board.append(piece_map[char])\n",
    "        elif char.isdigit():  # Keep numbers representing empty squares\n",
    "            bw_board.append(char)\n",
    "        elif char == '/':  # Keep row separators\n",
    "            bw_board.append('/')\n",
    "    \n",
    "    # Join the converted board layout into the final string\n",
    "    return ''.join(bw_board)\n",
    "\n",
    "def add_bw_board_fen(base_dir):\n",
    "    # Correct path to where the numbered folders are stored\n",
    "    numbered_folders_dir = os.path.join(base_dir, \"board_and_fen\")\n",
    "    \n",
    "    for folder_name in os.listdir(numbered_folders_dir):\n",
    "        folder_path = os.path.join(numbered_folders_dir, folder_name)\n",
    "        if os.path.isdir(folder_path):  # Ensure it's a folder\n",
    "            fen_file = os.path.join(folder_path, 'board.fen')\n",
    "            bw_fen_file = os.path.join(folder_path, 'bw_board.fen')\n",
    "            \n",
    "            if os.path.exists(fen_file):\n",
    "                # Read the original FEN file\n",
    "                with open(fen_file, 'r') as file:\n",
    "                    original_fen = file.read().strip()\n",
    "                \n",
    "                # Convert to black/white FEN\n",
    "                bw_fen = fen_to_bw(original_fen)\n",
    "                \n",
    "                # Write the black/white FEN to a new file\n",
    "                with open(bw_fen_file, 'w') as file:\n",
    "                    file.write(bw_fen)\n",
    "                print(f\"Created: {bw_fen_file}\")\n",
    "\n",
    "# Set the base directory for the chess images\n",
    "base_dir = \"chess_images\"  # Adjust if your notebook is in a different location\n",
    "\n",
    "# Add the bw_board.fen file to each folder\n",
    "add_bw_board_fen(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca6b45c-a85e-422f-8d3f-7c6d2e4df224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labeling each square by looking at bw_fen and write in csv for each square\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Paths\n",
    "base_dir = \"chess_images/board_and_fen/\"\n",
    "output_dir = \"chess_images/labels/\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to parse FEN and generate labels\n",
    "def parse_fen(fen, output_subfolder, board_name):\n",
    "    rows = fen.strip().split(\"/\")\n",
    "    for row_idx, row in enumerate(rows):\n",
    "        col_idx = 0\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                # Empty squares\n",
    "                for _ in range(int(char)):\n",
    "                    square_name = f\"r{row_idx}_c{col_idx}.csv\"\n",
    "                    square_output_dir = os.path.join(output_subfolder, board_name)\n",
    "                    os.makedirs(square_output_dir, exist_ok=True)\n",
    "                    with open(os.path.join(square_output_dir, square_name), \"w\", newline=\"\") as csvfile:\n",
    "                        writer = csv.writer(csvfile)\n",
    "                        writer.writerow([\"label\"])\n",
    "                        writer.writerow([\"none\"])  # Empty square\n",
    "                    col_idx += 1\n",
    "            else:\n",
    "                # Black ('b') or White ('w') piece\n",
    "                square_name = f\"r{row_idx}_c{col_idx}.csv\"\n",
    "                label = \"black\" if char == \"b\" else \"white\"\n",
    "                square_output_dir = os.path.join(output_subfolder, board_name)\n",
    "                os.makedirs(square_output_dir, exist_ok=True)\n",
    "                with open(os.path.join(square_output_dir, square_name), \"w\", newline=\"\") as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow([\"label\"])\n",
    "                    writer.writerow([label])\n",
    "                col_idx += 1\n",
    "\n",
    "# Process each subfolder\n",
    "for subfolder in os.listdir(base_dir):\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "    if os.path.isdir(subfolder_path):  # Ensure it's a directory\n",
    "        output_subfolder = os.path.join(output_dir, subfolder)\n",
    "        os.makedirs(output_subfolder, exist_ok=True)\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            if file == \"bw_board.fen\":\n",
    "                with open(os.path.join(subfolder_path, file), \"r\") as fen_file:\n",
    "                    fen = fen_file.read()\n",
    "                # Parse the FEN and generate labels for each board\n",
    "                board_name = os.path.splitext(file)[0]\n",
    "                parse_fen(fen, output_subfolder, board_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b9f3e7-9493-4e19-ae7b-b2cd7f279842",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'chess_images/prepared_data/svm_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([label_mapping[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels])\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Save the dataset as a .npy file\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData preparation complete. Saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\numpy\\lib\\npyio.py:525\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    524\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 525\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    528\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chess_images/prepared_data/svm_data.npy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Base directory paths\n",
    "squares_dir = \"chess_images/squares/\"\n",
    "labels_dir = \"chess_images/labels/\"\n",
    "output_file = \"chess_images/prepared_data/svm_data.npy\"  # Final dataset file\n",
    "\n",
    "# Function to extract image features (flattened grayscale pixel values)\n",
    "def extract_features(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (60, 60))  # Ensure uniform size\n",
    "    return image.flatten()  # Flatten the image into a feature vector\n",
    "\n",
    "# Function to load labels from a CSV file\n",
    "def load_label(labels_dir, subfolder, row, col):\n",
    "    label_path = os.path.join(labels_dir, subfolder, \"bw_board\", f\"r{row}_c{col}.csv\")\n",
    "    try:\n",
    "        with open(label_path, \"r\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Skip header\n",
    "            return next(reader)[0]  # Return the label (\"white\", \"black\", or \"none\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Label not found: {label_path}\")\n",
    "        return \"none\"\n",
    "\n",
    "# Function to parse row and column from filenames\n",
    "def parse_row_col(filename):\n",
    "    match = re.match(r\"r(\\d+)_c(\\d+)\", filename)\n",
    "    if match:\n",
    "        return int(match.group(1)), int(match.group(2))\n",
    "    else:\n",
    "        raise ValueError(f\"Filename format error: {filename}\")\n",
    "\n",
    "# Prepare the dataset\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all folders and boards\n",
    "for subfolder in os.listdir(squares_dir):\n",
    "    subfolder_path = os.path.join(squares_dir, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for board_folder in os.listdir(subfolder_path):\n",
    "            board_path = os.path.join(subfolder_path, board_folder)\n",
    "            if os.path.isdir(board_path):\n",
    "                for square_image in os.listdir(board_path):\n",
    "                    if square_image.endswith(\".jpg\"):\n",
    "                        image_path = os.path.join(board_path, square_image)\n",
    "                        \n",
    "                        try:\n",
    "                            # Parse row and column from the filename\n",
    "                            row, col = parse_row_col(square_image)\n",
    "                        except ValueError as e:\n",
    "                            print(e)\n",
    "                            continue\n",
    "                        \n",
    "                        # Extract features and load labels\n",
    "                        features.append(extract_features(image_path))\n",
    "                        labels.append(load_label(labels_dir, subfolder, row, col))\n",
    "\n",
    "# Convert features and labels into numpy arrays for SVM training\n",
    "X = np.array(features)\n",
    "\n",
    "label_mapping = {\"white\": 1, \"black\": -1, \"none\": 0}\n",
    "y = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "# Save the dataset as a .npy file\n",
    "np.save(output_file, {\"features\": X, \"labels\": y})\n",
    "\n",
    "print(f\"Data preparation complete. Saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca089cb-aca9-4954-8f5a-267046a7f680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 17600\n",
      "Feature vector size (per sample): 1296\n",
      "Number of labels: 17600\n",
      "\n",
      "Sample features (first 3):\n",
      "[[0.45375777 0.0822181  0.13528498 ... 0.1100283  0.         0.        ]\n",
      " [0.44317712 0.06178785 0.03534978 ... 0.21279086 0.18196391 0.06203866]\n",
      " [0.43382379 0.21830514 0.15788306 ... 0.14637069 0.         0.06495047]]\n",
      "\n",
      "Sample labels (first 3):\n",
      "[ 0  0 -1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the saved data\n",
    "data = np.load(\"chess_images/prepared_data/hog_svm_data.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Extract features and labels\n",
    "features = data[\"features\"]\n",
    "labels = data[\"labels\"]\n",
    "\n",
    "# Display the shapes of the datasets\n",
    "print(f\"Number of samples: {features.shape[0]}\")\n",
    "print(f\"Feature vector size (per sample): {features.shape[1]}\")\n",
    "print(f\"Number of labels: {len(labels)}\")\n",
    "\n",
    "# Display a few samples\n",
    "print(\"\\nSample features (first 3):\")\n",
    "print(features[:3])  # Print the first three feature vectors\n",
    "\n",
    "print(\"\\nSample labels (first 3):\")\n",
    "print(labels[:3])  # Print the first three labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba4462b-ed18-40e8-b0cf-8736d4ba1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e7487a-823e-448d-99e0-012677c60aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d80f9ef1-d0cf-4832-af11-f282d5a85354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel='linear', C=1.0)  # Adjust `C` and kernel as needed\n",
    "svm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7005cdf1-dd6e-4b6c-a035-47526beb0211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6529794692038057\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.41      0.45      1024\n",
      "           0       0.73      0.96      0.83      1894\n",
      "           1       0.57      0.35      0.43      1076\n",
      "\n",
      "    accuracy                           0.65      3994\n",
      "   macro avg       0.60      0.57      0.57      3994\n",
      "weighted avg       0.63      0.65      0.62      3994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5699e821-1e61-4228-b25d-c0b104c0e8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete. Saved to chess_images/prepared_data/hog_svm_data.npy.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Base directory paths\n",
    "squares_dir = \"chess_images/squares/\"\n",
    "labels_dir = \"chess_images/labels/\"\n",
    "output_file = \"chess_images/prepared_data/hog_svm_data.npy\"  # Final dataset file\n",
    "\n",
    "def extract_hog_features(image_path):\n",
    "    # Read the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize image to a consistent size (60x60)\n",
    "    image = cv2.resize(image, (60, 60))\n",
    "\n",
    "    # Compute HOG features (no need for multichannel argument)\n",
    "    fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "                         cells_per_block=(2, 2), visualize=True)\n",
    "    \n",
    "    # Return the feature descriptor (fd)\n",
    "    return fd\n",
    "\n",
    "# Function to load labels from a CSV file\n",
    "def load_label(labels_dir, subfolder, row, col):\n",
    "    label_path = os.path.join(labels_dir, subfolder, \"bw_board\", f\"r{row}_c{col}.csv\")\n",
    "    try:\n",
    "        with open(label_path, \"r\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Skip header\n",
    "            return next(reader)[0]  # Return the label (\"white\", \"black\", or \"none\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Label not found: {label_path}\")\n",
    "        return \"none\"\n",
    "\n",
    "# Function to parse row and column from filenames\n",
    "def parse_row_col(filename):\n",
    "    match = re.match(r\"r(\\d+)_c(\\d+)\", filename)\n",
    "    if match:\n",
    "        return int(match.group(1)), int(match.group(2))\n",
    "    else:\n",
    "        raise ValueError(f\"Filename format error: {filename}\")\n",
    "\n",
    "# Prepare the dataset\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all folders and boards\n",
    "for subfolder in os.listdir(squares_dir):\n",
    "    subfolder_path = os.path.join(squares_dir, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for board_folder in os.listdir(subfolder_path):\n",
    "            board_path = os.path.join(subfolder_path, board_folder)\n",
    "            if os.path.isdir(board_path):\n",
    "                for square_image in os.listdir(board_path):\n",
    "                    if square_image.endswith(\".jpg\"):\n",
    "                        image_path = os.path.join(board_path, square_image)\n",
    "                        \n",
    "                        try:\n",
    "                            # Parse row and column from the filename\n",
    "                            row, col = parse_row_col(square_image)\n",
    "                        except ValueError as e:\n",
    "                            print(e)\n",
    "                            continue\n",
    "                        \n",
    "                        # Extract HOG features and load labels\n",
    "                        features.append(extract_hog_features(image_path))\n",
    "                        labels.append(load_label(labels_dir, subfolder, row, col))\n",
    "\n",
    "# Convert features and labels into numpy arrays for SVM training\n",
    "X = np.array(features)\n",
    "\n",
    "label_mapping = {\"white\": 1, \"black\": -1, \"none\": 0}\n",
    "y = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "# Save the dataset as a .npy file\n",
    "np.save(output_file, {\"features\": X, \"labels\": y})\n",
    "\n",
    "print(f\"Data preparation complete. Saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738e3851-ee8d-4382-ad3c-0db6449046bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Perform cross-validation for each model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 24\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Mean Accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Std Dev = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:347\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    343\u001b[0m _check_groups_routing_disabled(groups)\n\u001b[0;32m    345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m indexable(X, y)\n\u001b[1;32m--> 347\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    349\u001b[0m scorers \u001b[38;5;241m=\u001b[39m check_scoring(\n\u001b[0;32m    350\u001b[0m     estimator, scoring\u001b[38;5;241m=\u001b[39mscoring, raise_exc\u001b[38;5;241m=\u001b[39m(error_score \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m# For estimators, a MetadataRouter is created in get_metadata_routing\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# methods. For these router methods, we create the router to use\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# `process_routing` on it.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1234\u001b[0m     )\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\utils\\_tags.py:405\u001b[0m, in \u001b[0;36mget_tags\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[1;32m--> 405\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[0;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "#K Fold\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Load dataset\n",
    "data = np.load(\"chess_images/prepared_data/hog_svm_data.npy\", allow_pickle=True).item()\n",
    "X, y = data[\"features\"], data[\"labels\"]\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    # \"SVM\": SVC(kernel=\"linear\"),\n",
    "    # \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "}\n",
    "\n",
    "# Use Stratified K-Fold (better for classification tasks)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=kfold, scoring=\"accuracy\")\n",
    "    print(f\"{name}: Mean Accuracy = {scores.mean():.4f}, Std Dev = {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb924b62-ce79-4ee7-96c5-850e82905668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Mean Accuracy = 0.9756, Std Dev = 0.0033\n",
      "Saved SVM model to chess_images/prepared_data/svm_model.pkl\n",
      "Random Forest: Mean Accuracy = 0.9884, Std Dev = 0.0046\n",
      "Saved Random Forest model to chess_images/prepared_data/random_forest_model.pkl\n",
      "Best model saved to chess_images/prepared_data/best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#K Fold and Save Model\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Load dataset\n",
    "data = np.load(\"chess_images/prepared_data/hog_svm_data.npy\", allow_pickle=True).item()\n",
    "X, y = data[\"features\"], data[\"labels\"]\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"SVM\": SVC(kernel=\"linear\"),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "}\n",
    "\n",
    "# Use Stratified K-Fold (better for classification tasks)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation for each model and save the best one\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=kfold, scoring=\"accuracy\")\n",
    "    mean_score = scores.mean()\n",
    "    print(f\"{name}: Mean Accuracy = {mean_score:.4f}, Std Dev = {scores.std():.4f}\")\n",
    "\n",
    "    # Train model on the full dataset before saving\n",
    "    model.fit(X, y)\n",
    "    model_path = f\"chess_images/prepared_data/{name.lower().replace(' ', '_')}_model.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Saved {name} model to {model_path}\")\n",
    "\n",
    "    # Track the best model\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_model = model\n",
    "\n",
    "# Save the best model separately\n",
    "best_model_path = \"chess_images/prepared_data/best_model.pkl\"\n",
    "joblib.dump(best_model, best_model_path)\n",
    "print(f\"Best model saved to {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbb73d1-2142-496e-9d61-14dee2c53697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated FEN: 2bwbw2/ww4wb/wwbwwwbw/3bbb2/3wbb2/w6b/bbbbbbbb/8\n"
     ]
    }
   ],
   "source": [
    "#loading the model and testing input as 480*480 image and output as bw_fen file\n",
    "\n",
    "import joblib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('chess_images/prepared_data/svm_model.pkl')\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    image = cv2.resize(image, (60, 60))\n",
    "    fd, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "                cells_per_block=(2, 2), visualize=True)\n",
    "    return fd\n",
    "\n",
    "def split_and_predict_fen(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (480, 480))\n",
    "    step = 60\n",
    "    label_mapping_inverse = {1: \"w\", -1: \"b\", 0: \"1\"}  # FEN compatible labels\n",
    "    predictions = []\n",
    "\n",
    "    for row in range(8):\n",
    "        row_data = []\n",
    "        for col in range(8):\n",
    "            square = image[row * step:(row + 1) * step, col * step:(col + 1) * step]\n",
    "            features = extract_hog_features(square)\n",
    "            prediction = model.predict([features])[0]\n",
    "            row_data.append(label_mapping_inverse[prediction])\n",
    "        # Convert row data to FEN row format\n",
    "        fen_row = ''.join(row_data)\n",
    "        # Consolidate empty squares into numbers\n",
    "        compact_fen_row = ''\n",
    "        count = 0\n",
    "        for char in fen_row:\n",
    "            if char == '1':\n",
    "                count += 1\n",
    "            else:\n",
    "                if count > 0:\n",
    "                    compact_fen_row += str(count)\n",
    "                    count = 0\n",
    "                compact_fen_row += char\n",
    "        if count > 0:\n",
    "            compact_fen_row += str(count)\n",
    "        predictions.append(compact_fen_row)\n",
    "\n",
    "    # Join rows with '/' for the final FEN\n",
    "    fen_result = '/'.join(predictions)\n",
    "    return fen_result\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'chess_images/test1.jpg'\n",
    "fen_output = split_and_predict_fen(image_path)\n",
    "print(\"Generated FEN:\", fen_output)\n",
    "\n",
    "# Optionally, save the FEN to a file\n",
    "with open(\"generated_bw_fen.fen\", \"w\") as file:\n",
    "    file.write(fen_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a8d59f-d962-4d2b-a3f0-596396379eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated FEN: b2b1bb1/bbbb1bbb/2bb1bb1/4b3/4ww2/2ww1w2/www1w1ww/w1ww1ww1\n"
     ]
    }
   ],
   "source": [
    "#loading the model and testing input as 480*480 image and output as bw_fen file 2222222222222222\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('chess_images/prepared_data/lightgbm_model.pkl')\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    image = cv2.resize(image, (60, 60))\n",
    "    fd, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "                cells_per_block=(2, 2), visualize=True)\n",
    "    \n",
    "    # Convert features to a DataFrame with column names matching training data\n",
    "    feature_names = [f'feature_{i}' for i in range(len(fd))]  # Create feature names\n",
    "    return pd.DataFrame([fd], columns=feature_names)  # Wrap in DataFrame\n",
    "\n",
    "def split_and_predict_fen(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (480, 480))\n",
    "    step = 60\n",
    "    label_mapping_inverse = {1: \"w\", -1: \"b\", 0: \"1\"}  # FEN compatible labels\n",
    "    predictions = []\n",
    "\n",
    "    for row in range(8):\n",
    "        row_data = []\n",
    "        for col in range(8):\n",
    "            square = image[row * step:(row + 1) * step, col * step:(col + 1) * step]\n",
    "            features_df = extract_hog_features(square)  # Get features as DataFrame\n",
    "            prediction = model.predict(features_df)[0]  # Pass DataFrame instead of list\n",
    "            row_data.append(label_mapping_inverse[prediction])\n",
    "        # Convert row data to FEN row format\n",
    "        fen_row = ''.join(row_data)\n",
    "        # Consolidate empty squares into numbers\n",
    "        compact_fen_row = ''\n",
    "        count = 0\n",
    "        for char in fen_row:\n",
    "            if char == '1':\n",
    "                count += 1\n",
    "            else:\n",
    "                if count > 0:\n",
    "                    compact_fen_row += str(count)\n",
    "                    count = 0\n",
    "                compact_fen_row += char\n",
    "        if count > 0:\n",
    "            compact_fen_row += str(count)\n",
    "        predictions.append(compact_fen_row)\n",
    "\n",
    "    # Join rows with '/' for the final FEN\n",
    "    fen_result = '/'.join(predictions)\n",
    "    return fen_result\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'chess_images/chess232.jpg'\n",
    "fen_output = split_and_predict_fen(image_path)\n",
    "print(\"Generated FEN:\", fen_output)\n",
    "\n",
    "# Optionally, save the FEN to a file\n",
    "with open(\"generated_bw_fen.fen\", \"w\") as file:\n",
    "    file.write(fen_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "278c6b1b-5467-41e4-9046-937127b4c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Adjust the path to match where you uploaded the file\n",
    "data_path = 'chess_images/prepared_data/hog_svm_data.npy'\n",
    "data = np.load(data_path, allow_pickle=True).item()\n",
    "\n",
    "X = data[\"features\"]\n",
    "y = data[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345dc46e-d799-4e13-9875-46fd1558d989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label -1: 32000 samples\n",
      "Label 0: 64000 samples\n",
      "Label 1: 32000 samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = np.load(\"chess_images/prepared_data/hog_svm_data.npy\", allow_pickle=True).item()\n",
    "y = data[\"labels\"]\n",
    "\n",
    "# Count occurrences of each class\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "# Print results\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"Label {label}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b9d60d7-059c-43f5-b1fe-93fc1d7e9368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 21024, -1: 10512, 1: 10512})\n"
     ]
    }
   ],
   "source": [
    "#data augmentation for -1 and 1 labels\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Adjust the path to the file location in your Google Drive\n",
    "data_path = 'chess_images/prepared_data/hog_svm_data.npy'\n",
    "\n",
    "# Load the prepared data\n",
    "data = np.load(data_path, allow_pickle=True).item()\n",
    "\n",
    "\n",
    "# Extract features and labels\n",
    "X = data[\"features\"]\n",
    "y = data[\"labels\"]\n",
    "\n",
    "\n",
    "def augment_features(X, y, target_label, num_samples):\n",
    "    augmented_X, augmented_y = [], []\n",
    "    for i, (features, label) in enumerate(zip(X, y)):\n",
    "        if label == target_label:\n",
    "            for _ in range(num_samples):\n",
    "                # Add small noise to features\n",
    "                noisy_features = features + np.random.normal(0, 0.01, size=features.shape)\n",
    "                augmented_X.append(noisy_features)\n",
    "                augmented_y.append(label)\n",
    "    return np.vstack([X, np.array(augmented_X)]), np.hstack([y, np.array(augmented_y)])\n",
    "\n",
    "# Augment samples for label -1 and 1\n",
    "X_augmented, y_augmented = augment_features(X, y, target_label=-1, num_samples=2)\n",
    "X_augmented, y_augmented = augment_features(X_augmented, y_augmented, target_label=1, num_samples=2)\n",
    "X_augmented, y_augmented = augment_features(X_augmented, y_augmented, target_label=0, num_samples=2)\n",
    "\n",
    "# Check the new label distribution\n",
    "print(Counter(y_augmented))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9562af9f-25e4-418e-a8d9-5d69b63342d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 28\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_augmented\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_augmented\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     mean_score \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Mean Accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Std Dev = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:347\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    343\u001b[0m _check_groups_routing_disabled(groups)\n\u001b[0;32m    345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m indexable(X, y)\n\u001b[1;32m--> 347\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    349\u001b[0m scorers \u001b[38;5;241m=\u001b[39m check_scoring(\n\u001b[0;32m    350\u001b[0m     estimator, scoring\u001b[38;5;241m=\u001b[39mscoring, raise_exc\u001b[38;5;241m=\u001b[39m(error_score \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m# For estimators, a MetadataRouter is created in get_metadata_routing\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# methods. For these router methods, we create the router to use\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# `process_routing` on it.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1234\u001b[0m     )\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\utils\\_tags.py:405\u001b[0m, in \u001b[0;36mget_tags\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[1;32m--> 405\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\raspberryturk\\lib\\site-packages\\sklearn\\base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[0;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "#K Fold and Save Model\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Load dataset\n",
    "# data = np.load(\"chess_images/prepared_data/hog_svm_data.npy\", allow_pickle=True).item()\n",
    "# X, y = data[\"features\"], data[\"labels\"]\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    # \"SVM\": SVC(kernel=\"linear\"),\n",
    "    # \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "}\n",
    "\n",
    "# Use Stratified K-Fold (better for classification tasks)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation for each model and save the best one\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model,X_augmented, y_augmented, cv=kfold, scoring=\"accuracy\")\n",
    "    mean_score = scores.mean()\n",
    "    print(f\"{name}: Mean Accuracy = {mean_score:.4f}, Std Dev = {scores.std():.4f}\")\n",
    "\n",
    "    # Train model on the full dataset before saving\n",
    "    model.fit(X_augmented, y_augmented)\n",
    "    model_path = f\"chess_images/prepared_data/{name.lower().replace(' ', '_')}_model.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Saved {name} model to {model_path}\")\n",
    "\n",
    "    # Track the best model\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_model = model\n",
    "\n",
    "# Save the best model separately\n",
    "best_model_path = \"chess_images/prepared_data/best_model.pkl\"\n",
    "joblib.dump(best_model, best_model_path)\n",
    "print(f\"Best model saved to {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a6b197-ab0b-4129-a607-35d789b1115e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.99      0.99      3156\n",
      "           0       1.00      1.00      1.00      1908\n",
      "           1       0.99      0.98      0.99      3173\n",
      "\n",
      "    accuracy                           0.99      8237\n",
      "   macro avg       0.99      0.99      0.99      8237\n",
      "weighted avg       0.99      0.99      0.99      8237\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1609d382be0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf', C=10, gamma='scale')  # Try 'rbf' or 'poly' as well\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=svm_classifier.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d784e796-fda7-44ac-a11a-840300a3a5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(svm_classifier, 'svm_chess_model_test.pkl')\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ccec3-5daf-47c5-ba6e-6a18eab3f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Assuming you've already run the augmentation code, and your augmented dataset is in X_augmented, y_augmented\n",
    "\n",
    "# Check the new label distribution\n",
    "print(Counter(y_augmented))\n",
    "\n",
    "# Normalize the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_augmented = scaler.fit_transform(X_augmented)\n",
    "\n",
    "# Convert the labels to one-hot encoding for classification\n",
    "y_augmented = to_categorical(y_augmented, num_classes=3)  # Assuming 3 classes: -1, 0, 1\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build MLP model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer (Flatten the 1D feature vector into a single vector)\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))  # Input shape should match the number of features (1296)\n",
    "model.add(Dropout(0.5))  # Dropout layer for regularization\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer (for 3 classes)\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes: -1, 0, 1\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"chess_model_mlp.h5\")\n",
    "print(\"Model saved as chess_model_mlp.h5\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions and labels back to single class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65898ebe-3019-4f18-85a3-cff684b9f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlay process completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "base_dir = \"./chess_images/board_and_fen\"\n",
    "output_dir = \"output_with_fen\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Chessboard parameters\n",
    "board_size = 480\n",
    "square_size = board_size // 8\n",
    "\n",
    "# Function to read FEN file and convert to 8x8 array\n",
    "def read_fen_file(fen_file_path):\n",
    "    with open(fen_file_path, 'r') as file:\n",
    "        fen_content = file.read().strip()\n",
    "\n",
    "    # Convert FEN string into an 8x8 list of squares\n",
    "    fen_rows = fen_content.split('/')\n",
    "    board = []\n",
    "    for row in fen_rows:\n",
    "        expanded_row = []\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                expanded_row.extend([''] * int(char))\n",
    "            else:\n",
    "                expanded_row.append(char)\n",
    "        board.append(expanded_row)\n",
    "    return board\n",
    "\n",
    "# Overlay text on the image\n",
    "def overlay_fen_on_image(image, board):\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            piece = board[i][j]\n",
    "            if piece:\n",
    "                color = (0, 0, 255) if piece == 'b' else (255, 255, 255)  # Red for black, White for white\n",
    "                text_position = (j * square_size + 20, i * square_size + 40)\n",
    "                cv2.putText(image, piece, text_position, cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    return image\n",
    "\n",
    "# Process each folder 0-54\n",
    "for folder in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    # Read FEN file\n",
    "    fen_file_path = os.path.join(folder_path, \"bw_board.fen\")\n",
    "    if not os.path.exists(fen_file_path):\n",
    "        print(f\"FEN file not found in {folder}\")\n",
    "        continue\n",
    "\n",
    "    board = read_fen_file(fen_file_path)\n",
    "\n",
    "    # Read one image (you can customize this to pick a specific image if needed)\n",
    "    image_path = None\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(('.jpg', '.png')):\n",
    "            image_path = os.path.join(folder_path, file)\n",
    "            break\n",
    "\n",
    "    if image_path is None:\n",
    "        print(f\"No image found in {folder}\")\n",
    "        continue\n",
    "\n",
    "    # Read and resize image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (board_size, board_size))\n",
    "\n",
    "    # Overlay FEN text\n",
    "    image_with_fen = overlay_fen_on_image(image, board)\n",
    "\n",
    "    # Save output\n",
    "    output_path = os.path.join(output_dir, f\"{folder}.jpg\")\n",
    "    cv2.imwrite(output_path, image_with_fen)\n",
    "\n",
    "print(\"Overlay process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d26931b-127d-4d36-a2c7-99bbe5cd9019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation process complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Augmentation functions\n",
    "def adjust_brightness(img, factor=0.2):\n",
    "    \"\"\"Adjust brightness of the image.\"\"\"\n",
    "    return cv2.convertScaleAbs(img, alpha=1, beta=random.uniform(-factor*255, factor*255))\n",
    "\n",
    "def add_gaussian_noise(img, mean=0, std=10):\n",
    "    \"\"\"Add Gaussian noise to the image.\"\"\"\n",
    "    noise = np.random.normal(mean, std, img.shape).astype(np.int16)\n",
    "    noisy_img = np.clip(img + noise, 0, 255).astype(np.uint8)\n",
    "    return noisy_img\n",
    "\n",
    "def adjust_contrast(img, factor_range=(0.8, 1.2)):\n",
    "    \"\"\"Adjust contrast of the image.\"\"\"\n",
    "    factor = random.uniform(*factor_range)\n",
    "    mean = np.mean(img)\n",
    "    return np.clip((img - mean) * factor + mean, 0, 255).astype(np.uint8)\n",
    "\n",
    "def color_jitter(img, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1):\n",
    "    \"\"\"Randomly change the color properties (brightness, contrast, saturation, hue).\"\"\"\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Adjust Hue\n",
    "    hsv[..., 0] = np.clip(hsv[..., 0] + random.uniform(-hue, hue) * 255, 0, 255)\n",
    "\n",
    "    # Adjust Saturation\n",
    "    hsv[..., 1] = np.clip(hsv[..., 1] * random.uniform(1 - saturation, 1 + saturation), 0, 255)\n",
    "\n",
    "    # Adjust Value (Brightness)\n",
    "    hsv[..., 2] = np.clip(hsv[..., 2] * random.uniform(1 - brightness, 1 + brightness), 0, 255)\n",
    "\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Adjust contrast by scaling the pixels\n",
    "    img = cv2.convertScaleAbs(img, alpha=random.uniform(1 - contrast, 1 + contrast), beta=0)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Paths\n",
    "input_folder = 'processed_images'  # Source folder (original data)\n",
    "output_folder = 'board_and_fen_augmented'     # Target folder (augmented data)\n",
    "\n",
    "# Create output folder if not exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for i in range(55):\n",
    "    input_folder_path = os.path.join(input_folder, str(i))\n",
    "    output_folder_path = os.path.join(output_folder, str(i))\n",
    "\n",
    "    if not os.path.exists(input_folder_path):\n",
    "        print(f\"Skipping folder {i} (does not exist)\")\n",
    "        continue\n",
    "\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "    images = sorted([f for f in os.listdir(input_folder_path) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "    if len(images) < 1:\n",
    "        print(f\"Folder {i} has no images — skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load the first image\n",
    "    original_image_path = os.path.join(input_folder_path, images[0])\n",
    "    img = cv2.imread(original_image_path)\n",
    "\n",
    "    # Generate 20 images using different augmentations\n",
    "    for j in range(20):\n",
    "        augmented = img.copy()\n",
    "\n",
    "        # Apply random augmentations\n",
    "        if random.random() > 0.5:\n",
    "            augmented = adjust_brightness(augmented)\n",
    "        if random.random() > 0.5:\n",
    "            augmented = add_gaussian_noise(augmented)\n",
    "        if random.random() > 0.5:\n",
    "            augmented = adjust_contrast(augmented)\n",
    "        if random.random() > 0.5:\n",
    "            augmented = color_jitter(augmented)\n",
    "\n",
    "        # Save the augmented image\n",
    "        augmented_image_path = os.path.join(output_folder_path, f\"augmented_{j+1}.jpg\")\n",
    "        cv2.imwrite(augmented_image_path, augmented)\n",
    "\n",
    "    # Copy the bw_board.fen file directly (if exists)\n",
    "    fen_file_path = os.path.join(input_folder_path, 'bw_board.fen')\n",
    "    if os.path.exists(fen_file_path):\n",
    "        output_fen_file_path = os.path.join(output_folder_path, 'bw_board.fen')\n",
    "        with open(fen_file_path, 'r') as src, open(output_fen_file_path, 'w') as dst:\n",
    "            dst.write(src.read())\n",
    "\n",
    "print(\"Augmentation process complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ce0a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation process complete.\n"
     ]
    }
   ],
   "source": [
    "#5 images augumentation (main)\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Augmentation functions\n",
    "def adjust_brightness(img, factor=0.2):\n",
    "    return cv2.convertScaleAbs(img, alpha=1, beta=random.uniform(-factor * 255, factor * 255))\n",
    "\n",
    "def add_gaussian_noise(img, mean=0, std=10):\n",
    "    noise = np.random.normal(mean, std, img.shape).astype(np.int16)\n",
    "    return np.clip(img + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "def adjust_contrast(img, factor_range=(0.8, 1.2)):\n",
    "    factor = random.uniform(*factor_range)\n",
    "    mean = np.mean(img)\n",
    "    return np.clip((img - mean) * factor + mean, 0, 255).astype(np.uint8)\n",
    "\n",
    "def color_jitter(img, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv[..., 0] = np.clip(hsv[..., 0] + random.uniform(-hue, hue) * 255, 0, 255)\n",
    "    hsv[..., 1] = np.clip(hsv[..., 1] * random.uniform(1 - saturation, 1 + saturation), 0, 255)\n",
    "    hsv[..., 2] = np.clip(hsv[..., 2] * random.uniform(1 - brightness, 1 + brightness), 0, 255)\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return cv2.convertScaleAbs(img, alpha=random.uniform(1 - contrast, 1 + contrast), beta=0)\n",
    "\n",
    "# Paths\n",
    "input_folder = './chess_images/board_and_fen'\n",
    "output_folder = './augumented_train_images/board_and_fen_train_50images'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for i in range(0, 101):  # Loop through 20 subfolders\n",
    "    input_folder_path = os.path.join(input_folder, str(i))\n",
    "    output_folder_path = os.path.join(output_folder, str(i))\n",
    "\n",
    "    if not os.path.exists(input_folder_path):\n",
    "        print(f\"Skipping folder {i} (does not exist)\")\n",
    "        continue\n",
    "\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "    images = sorted([f for f in os.listdir(input_folder_path) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "    if len(images) != 5:\n",
    "        print(f\"Folder {i} does not contain exactly 5 images — skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Process each of the 5 images\n",
    "    for img_index, image_name in enumerate(images):\n",
    "        original_image_path = os.path.join(input_folder_path, image_name)\n",
    "        img = cv2.imread(original_image_path)\n",
    "\n",
    "        # Save the original image directly\n",
    "        cv2.imwrite(os.path.join(output_folder_path, image_name), img)\n",
    "\n",
    "        # Generate 4 augmented versions per image\n",
    "        for j in range(9):\n",
    "            augmented = img.copy()\n",
    "\n",
    "            # Apply random augmentations (you can customize this part)\n",
    "            if random.random() > 0.5:\n",
    "                augmented = adjust_brightness(augmented)\n",
    "            if random.random() > 0.5:\n",
    "                augmented = add_gaussian_noise(augmented)\n",
    "            if random.random() > 0.5:\n",
    "                augmented = adjust_contrast(augmented)\n",
    "            if random.random() > 0.5:\n",
    "                augmented = color_jitter(augmented)\n",
    "\n",
    "            augmented_image_path = os.path.join(output_folder_path, f\"{image_name.split('.')[0]}_augmented_{j+1}.jpg\")\n",
    "            cv2.imwrite(augmented_image_path, augmented)\n",
    "\n",
    "    # Copy the bw_board.fen file if it exists\n",
    "    fen_file_path = os.path.join(input_folder_path, 'bw_board.fen')\n",
    "    if os.path.exists(fen_file_path):\n",
    "        output_fen_file_path = os.path.join(output_folder_path, 'bw_board.fen')\n",
    "        with open(fen_file_path, 'r') as src, open(output_fen_file_path, 'w') as dst:\n",
    "            dst.write(src.read())\n",
    "\n",
    "print(\"Augmentation process complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a3ab59-8a48-4e65-944d-fa040b85ae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Process completed — images and FEN files copied to 'processed_images/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "source_folder = './chess_images/board_and_fen'\n",
    "target_folder = 'processed_images'\n",
    "\n",
    "# Create target folder if it doesn't exist\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "for folder_num in range(55):\n",
    "    src_folder = os.path.join(source_folder, str(folder_num))\n",
    "    dst_folder = os.path.join(target_folder, str(folder_num))\n",
    "\n",
    "    os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "    images = [f for f in os.listdir(src_folder) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    if not images:\n",
    "        print(f\"No images found in folder {folder_num}\")\n",
    "        continue\n",
    "\n",
    "    # Choose 1 image (can do random.choice or just take the first)\n",
    "    selected_image = random.choice(images)  # or images[0] if you prefer fixed order\n",
    "    shutil.copy2(os.path.join(src_folder, selected_image), os.path.join(dst_folder, selected_image))\n",
    "\n",
    "    # Copy the bw_board.fen file too\n",
    "    fen_file = os.path.join(src_folder, 'bw_board.fen')\n",
    "    if os.path.exists(fen_file):\n",
    "        shutil.copy2(fen_file, os.path.join(dst_folder, 'bw_board.fen'))\n",
    "    else:\n",
    "        print(f\"No FEN file found in folder {folder_num}\")\n",
    "\n",
    "print(\"✅ Process completed — images and FEN files copied to 'processed_images/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c932e-9866-499f-aa96-370cd9a0a6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raspberryturk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
